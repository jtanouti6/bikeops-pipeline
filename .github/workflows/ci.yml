name: CI                    # Nom qui apparaîtra sous l’onglet Actions

on:                         # Quand déclencher la CI
  push:
    branches: [ main, develop ]        # commits poussés sur main/develop
  pull_request:
    branches: [ main, develop ]        # ouvertures/mises à jour de PR vers main/develop

jobs:                       # Un workflow = plusieurs jobs (indépendants par défaut)

  lint:                     # 1er job : linting via pre-commit
    name: lint (pre-commit) # Le libellé exact visible comme "check" côté GitHub
    runs-on: ubuntu-latest  # Runner GitHub hébergé (VM Linux éphémère)
    steps:                  # Les étapes s’exécutent séquentiellement *dans ce runner*
      - name: Checkout
        uses: actions/checkout@v4      # Récupère ton code dans le runner

      - name: Set up Python 3.11
        uses: actions/setup-python@v5  # Installe Python 3.11 dans la VM
        with:
          python-version: "3.11"

      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1 # Exécute les hooks déclarés dans .pre-commit-config.yaml
                                       # (ruff, black, isort...) sur les fichiers modifiés

  spark-smoke:              # 2e job : “test fumée” que Spark démarre bien
    name: spark-smoke (PySpark + Java 17)
    runs-on: ubuntu-latest
    needs: lint             # ⚠️ Ce job n’exécute que si le job "lint" a réussi
    env:                    # Variables d’environnement utiles à Spark en local
      SPARK_LOCAL_IP: 127.0.0.1
      PYSPARK_PYTHON: python
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4          # Cache des wheel pip pour accélérer les runs
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Set up Java 17 (Temurin)
        uses: actions/setup-java@v4     # Installe un JDK 17 (Temurin) requis par Spark
        with:
          distribution: temurin
          java-version: "17"

      - name: Install runtime deps
        run: |                          # Installe les dépendances runtime
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: PySpark smoke             # Petit script inline : crée/stoppe une session Spark
        run: |
          python - <<'PY'
          from pyspark.sql import SparkSession
          spark = (SparkSession.builder
                   .master("local[*]")
                   .appName("ci-smoke")
                   .config("spark.sql.session.timeZone","UTC")
                   .getOrCreate())
          print("Spark version:", spark.version)
          spark.stop()
          PY
  pytest:
    name: pytest
    runs-on: ubuntu-latest
    needs: spark-smoke
    env:
    SPARK_LOCAL_IP: 127.0.0.1
    PYSPARK_PYTHON: python
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11
      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip
      - name: Set up Java 17 (Temurin)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17
      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.tx
      - name: Run pytest
        run: pytest -q
