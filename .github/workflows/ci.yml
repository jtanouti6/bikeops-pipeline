name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  lint:
    name: lint (pre-commit)
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # Exécute les hooks .pre-commit (ruff/black/isort) sur le diff
      - name: Run pre-commit
        uses: pre-commit/action@v3.0.1

  spark-smoke:
    name: spark-smoke (PySpark + Java 17)
    runs-on: ubuntu-latest
    needs: lint
    env:
      SPARK_LOCAL_IP: 127.0.0.1
      PYSPARK_PYTHON: python
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Set up Java 17 (Temurin)
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: "17"

      - name: Install runtime deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Démarre/stoppe une session Spark pour valider l’environnement
      - name: PySpark smoke
        run: |
          python - <<'PY'
          from pyspark.sql import SparkSession
          spark = (SparkSession.builder
                   .master("local[*]")
                   .appName("ci-smoke")
                   .config("spark.sql.session.timeZone","UTC")
                   .getOrCreate())
          print("Spark version:", spark.version)
          spark.stop()
          PY
